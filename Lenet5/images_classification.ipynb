{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Load in relevant libraries, and alias where appropriate\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "# Device will determine whether to run the training on GPU or CPU.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Đầu tiên, dữ liệu MNIST không thể được sử dụng như dữ liệu dành cho kiến ​​trúc LeNet5.Kiến trúc LeNet5 chấp nhận đầu vào là 32x32 và hình ảnh MNIST là 28x28.\n",
    "+ Chúng ta có thể khắc phục điều này bằng cách thay đổi kích thước hình ảnh, chuẩn hóa chúng bằng cách sử dụng giá trị trung bình và độ lệch chuẩn được tính toán trước (có sẵn trực tuyến) và cuối cùng lưu trữ chúng dưới dạng tenxơ"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lenet5 from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNeuralNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc = nn.Linear(400, 120)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(120, 84)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNeuralNet( num_classes).to(device)\n",
    "\n",
    "#Defining cost and optimizer\n",
    "cost = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.1406\n",
      "Epoch [1/10], Step [800/938], Loss: 0.0999\n",
      "Epoch [2/10], Step [400/938], Loss: 0.0344\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0026\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0321\n",
      "Epoch [3/10], Step [800/938], Loss: 0.0234\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0409\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0182\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0104\n",
      "Epoch [5/10], Step [800/938], Loss: 0.0017\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0076\n",
      "Epoch [6/10], Step [800/938], Loss: 0.1692\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0014\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0025\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0012\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0016\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0055\n",
      "Epoch [9/10], Step [800/938], Loss: 0.1826\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0049\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "            #Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = cost(outputs, labels)\n",
    "        \t\n",
    "        \t# Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \t\t\n",
    "        if (i+1) % 400 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "        \t\t           .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 99.19 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\t "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
